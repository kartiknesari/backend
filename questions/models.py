# questions/models.py
import uuid
from django.db import models
from django.core.validators import MinValueValidator, MaxValueValidator
from django.utils.text import slugify


# ----------------------------------------------------------------------
# 1. Domain – Chemical, Mechanical, Textiles, etc.
# ----------------------------------------------------------------------
class Domain(models.Model):
    """
    Represent a technical domain or subject area (for example: "chemical", "mechanical", "textiles", "civil").

    Fields
    - id (UUID): Primary key, generated by uuid.uuid4(), not editable.
    - slug (str): URL-safe, unique identifier (SlugField). If not provided, it is auto-generated from `name` in save().
    - name (str): Human-readable, unique name for the domain.
    - description (str): Optional free-text description.
    - is_active (bool): Indicates whether the domain is active; defaults to True.

    Behavior
    - save(): Ensures `slug` is populated by slugifying `name` when `slug` is empty, then delegates to the parent save.
    - __str__(): Returns the domain's `name`.

    Meta
    - verbose_name set to "Domain".
    - Default ordering is by `name`.
    """

    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    slug = models.SlugField(max_length=50, unique=True, help_text="URL-safe identifier")
    name = models.CharField(max_length=100, unique=True)
    description = models.TextField(blank=True)
    is_active = models.BooleanField(default=True)

    class Meta:
        verbose_name = "Domain"
        ordering = ["name"]

    def save(self, *args, **kwargs):
        if not self.slug:
            self.slug = slugify(self.name)
        super().save(*args, **kwargs)

    def __str__(self):
        return self.name


# ----------------------------------------------------------------------
# 2. Topic – Sub-category inside a domain
# ----------------------------------------------------------------------
class Topic(models.Model):
    """
    Sub-category within a Domain (e.g., "Fluid Mechanics" under "Chemical Engineering").

    Fields
    ------
    id : UUIDField
        Auto-generated primary key.
    domain : ForeignKey(Domain)
        Parent domain. Required.
    slug : SlugField(max_length=100)
        URL-safe identifier. Auto-generated from `name` if blank.
    name : CharField(max_length=150)
        Human-readable topic name. Required.
    description : TextField
        Optional detailed description.

    Constraints
    -----------
    unique_together = ('domain', 'slug')
    ordering = ['name']

    Behavior
    --------
    - `slug` is auto-populated via `slugify(name)` on save if not set.
    - `__str__` returns: "{domain.name} → {name}"

    Example
    -------
    "Chemical Engineering → Fluid Mechanics"
    """

    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    domain = models.ForeignKey(Domain, on_delete=models.CASCADE, related_name="topics")
    slug = models.SlugField(max_length=100)
    name = models.CharField(max_length=150)
    description = models.TextField(blank=True)

    class Meta:
        unique_together = ("domain", "slug")
        ordering = ["name"]

    def save(self, *args, **kwargs):
        if not self.slug:
            self.slug = slugify(self.name)
        super().save(*args, **kwargs)

    def __str__(self):
        return f"{self.domain.name} → {self.name}"


# ----------------------------------------------------------------------
# 3. Question – Core entity
# ----------------------------------------------------------------------
class Question(models.Model):
    """
    Core assessment item for engineering employment testing.

    Fields
    ------
    id : UUIDField, Auto-generated primary key.
    domain : ForeignKey(Domain, PROTECT), Required. Links to engineering discipline.
    topic : ForeignKey(Topic, SET_NULL), Optional. Further categorizes question.
    type : CharField(max_length=5, choices=QUESTION_TYPES), Question format: mcq, num, case, diag. Indexed for filtering.
    text : TextField, Question prompt. LaTeX supported (use $$ for display math).
    explanation : TextField, Optional solution shown after grading.
    difficulty : PositiveSmallIntegerField(1–5), 1 = easy, 5 = expert.
    points : PositiveSmallIntegerField, Default 1. Score weight.
    time_estimate_seconds : PositiveSmallIntegerField, Default 120. Expected completion time.
    data : JSONField
        Type-specific payload:
          - MCQ:  {"options": [...], "correct": "A", "shuffle": true}
          - NUM:  {"answer": 42.0, "unit": "kPa", "tolerance": 0.02}
          - DIAG: {"image_url": "...", "hotspots": [...]}
          - CASE: {"rubric": {"criteria": "Safety", "max": 5}}
    created_by : ForeignKey(CustomUser, SET_NULL), Author (SME). Nullable.
    created_at / updated_at : DateTimeField, Auto-managed timestamps.
    is_active : BooleanField, Default True. Soft-delete flag.

    Constraints
    -----------
    Indexes: (domain, type), difficulty, topic
    Ordering: newest first (-created_at)

    Behavior
    --------
    - __str__ returns: "[Multiple Choice] Calculate mass flow..."
    - Safe type label via QUESTION_TYPES dict (avoids get_type_display errors)

    Example
    -------
    "[Numerical] Determine the heat transfer coefficient..."
    """

    QUESTION_TYPES = [
        ("mcq", "Multiple Choice"),
        ("num", "Numerical"),
        ("case", "Open-Ended"),
        ("diag", "Diagram"),
    ]

    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    domain = models.ForeignKey(
        Domain, on_delete=models.PROTECT, related_name="questions"
    )
    topic = models.ForeignKey(
        Topic,
        on_delete=models.SET_NULL,
        null=True,
        blank=True,
        related_name="questions",
    )
    type = models.CharField(max_length=5, choices=QUESTION_TYPES, db_index=True)

    # Core content
    text = models.TextField(help_text="LaTeX supported. Use $$ for display math.")
    explanation = models.TextField(
        blank=True, help_text="Solution / explanation shown after grading"
    )

    # Metadata
    difficulty = models.PositiveSmallIntegerField(
        validators=[MinValueValidator(1), MaxValueValidator(5)],
        help_text="1 = easy, 5 = expert",
    )
    points = models.PositiveSmallIntegerField(default=1, help_text="Score weight")
    time_estimate_seconds = models.PositiveSmallIntegerField(
        default=120, help_text="Expected time"
    )

    # Data payload (type-specific)
    data = models.JSONField(
        verbose_name="question_types_specific_adata",
        default=dict,
        help_text="""
        MCQ: {"options": ["A", "B", ...], "correct": "A", "shuffle": true}
        NUM: {"answer": 42.0, "unit": "kPa", "tolerance": 0.02}
        DIAG: {"image_url": "...", "hotspots": [{"x":10,"y":20,"label":"Pump"}]}
        CASE: {"rubric": {"criteria": "Safety", "max": 5}}
        SIM: {"scenario": "json", "expected_output": {...}}
        """,
    )

    # Auditing
    created_by = models.ForeignKey(
        "users.CustomUser",
        on_delete=models.SET_NULL,
        null=True,
        related_name="authored_questions",
    )
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    is_active = models.BooleanField(default=True)

    class Meta:
        indexes = [
            models.Index(fields=["domain", "type"]),
            models.Index(fields=["difficulty"]),
            models.Index(fields=["topic"]),
        ]
        ordering = ["-created_at"]

    def __str__(self):
        # Safe fallback
        type_label = dict(self.QUESTION_TYPES).get(self.type, self.type)
        preview = self.text[:60] + ("..." if len(self.text) > 60 else "")
        return f"[{type_label}] {preview}"
